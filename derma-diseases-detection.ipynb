{"cells":[{"metadata":{"_uuid":"43ca55a70a039aacf79978e04d3092b8070692b0"},"cell_type":"markdown","source":"# Derma Diseases Detection\n- Performs fine tuning on Keras VGG16 in order to detect derma diseases such as: nevus, melanoma and seborrheic_keratosis"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Import Keras with tensorflow backend\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import optimizers\nfrom keras.applications import VGG16\n\n# Import OpenCV\nimport cv2\n\n# Utility\nimport os\nimport numpy as np\nimport itertools\nimport random\nfrom collections import Counter\nfrom glob import iglob\n\n# Ignore warning\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Confusion Matrix & classification report\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Plot\nimport matplotlib.pyplot as plt\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7c9bfaa65afead7c7a729c882c216a38d4308ae"},"cell_type":"markdown","source":"### Settings\nDefine all settings usefull for next steps"},{"metadata":{"trusted":true,"_uuid":"def101af150814996046ecb87d4d65d93c1c8c1c"},"cell_type":"code","source":"# Set dataset folder path\nBASE_DATASET_FOLDER = os.path.join(\"..\",\"input\",\"derma_disease_dataset\",\"dataset\")\nTRAIN_FOLDER = \"train\"\nVALIDATION_FOLDER = \"validation\"\nTEST_FOLDER = \"test\"\n\n# ResNet50 image size\nIMAGE_SIZE = (224, 224)\nINPUT_SHAPE = (224, 224, 3)\n\n# Keras settings\nTRAIN_BATCH_SIZE = 64\nVAL_BATCH_SIZE = 8\nEPOCHS = 50\nLEARNING_RATE = 0.0001\nMODEL_PATH = os.path.join(\"derma_diseases_detection.h5\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac16d3a273f5a9e8c4d260495705f624ce65fd40"},"cell_type":"markdown","source":"### Data agumentation\nRead images in batches directly from folders and perform data augmentation"},{"metadata":{"trusted":true,"_uuid":"03df15fd15f5c40bf7e15867a4315755e95bdd3e"},"cell_type":"code","source":"def percentage_value(pct, allvals):\n    absolute = int(pct/100.*np.sum(allvals))\n    return \"{:.1f}%\\n({:d})\".format(pct, absolute)\n\ndef plot_dataset_description(path, title):\n    classes = []\n    for filename in iglob(os.path.join(path, \"**\",\"*.jpg\")):\n        classes.append(os.path.split(os.path.split(filename)[0])[-1])\n\n    classes_cnt = Counter(classes)\n    values = list(classes_cnt.values())\n    labels = list(classes_cnt.keys())\n\n    plt.figure(figsize=(8,8))\n    plt.pie(values, labels=labels, autopct=lambda pct: percentage_value(pct, values), \n            shadow=True, startangle=140)\n\n    plt.title(title)    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20a5d5b36135a84ad1fa7505f9dce08f8ae2e353"},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(\n        os.path.join(BASE_DATASET_FOLDER, TRAIN_FOLDER),\n        target_size=IMAGE_SIZE,\n        batch_size=TRAIN_BATCH_SIZE,\n        class_mode='categorical', \n        shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c6050694270a66eb3d7edb0862ca49da6d6b3c8"},"cell_type":"code","source":"plot_dataset_description(os.path.join(BASE_DATASET_FOLDER, TRAIN_FOLDER), \"Train folder description\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17273d4f99e3cd7d8b0cf50456b9ea42dc45f777"},"cell_type":"code","source":"val_datagen = ImageDataGenerator(rescale=1./255)\nval_generator = val_datagen.flow_from_directory(\n        os.path.join(BASE_DATASET_FOLDER, VALIDATION_FOLDER),\n        target_size=IMAGE_SIZE,\n        class_mode='categorical', \n        shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"015bec813daf44485a5a275ebd254040df910940"},"cell_type":"code","source":"plot_dataset_description(os.path.join(BASE_DATASET_FOLDER, VALIDATION_FOLDER), \"Validation folder description\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67c33f4450400e3a9eb6d3949b0484b016af0b11"},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n        os.path.join(BASE_DATASET_FOLDER, TEST_FOLDER),\n        target_size=IMAGE_SIZE,\n        batch_size=VAL_BATCH_SIZE,\n        class_mode='categorical', \n        shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e59825c4f4a0b03c277c08b99b560cbf745688b"},"cell_type":"code","source":"plot_dataset_description(os.path.join(BASE_DATASET_FOLDER, TEST_FOLDER), \"Test folder description\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b91d02eed8fb25b079ce2e76e8b715a184b53c3a"},"cell_type":"code","source":"classes = {v: k for k, v in train_generator.class_indices.items()}\nprint(classes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b114cb078971946f0de25c09f66283c1c13fea42"},"cell_type":"markdown","source":"### Load VGG16 model\nLoad the pre-trained VGG16 model without the top layer"},{"metadata":{"trusted":true,"_uuid":"25cf5125ecffd5dc9c8783e4d1bee85a7b6462f0"},"cell_type":"code","source":"vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a17def61317c283bbe3cbb9d7da838ebcfa5334e"},"cell_type":"markdown","source":"### Freeze the layers except the last 4 layers"},{"metadata":{"trusted":true,"_uuid":"54882693630c04c3cc5096e4d797b3ed7461daa4"},"cell_type":"code","source":"for layer in vgg_model.layers[:-4]:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"343e7eb05214396cc511d5e8a84c4c2ada95633a"},"cell_type":"markdown","source":"### Create model"},{"metadata":{"trusted":true,"_uuid":"144c009352db304b07d3bb7575f537f9d05b83fe","_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"# Create the model\nmodel = Sequential()\n \n# Add the vgg convolutional base model\nmodel.add(vgg_model)\n \n# Add new layers\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(classes), activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f20e29a6a98d740a35ae251aa9b2102f2a2fc91"},"cell_type":"code","source":"# Show a summary of the model. Check the number of trainable parameters\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3ab49d817bb3fe1710de9ec56de494d0b81e6ce"},"cell_type":"markdown","source":"### Compile model\nCompile model specifying the optimizer learning rate"},{"metadata":{"trusted":true,"_uuid":"2fd90b88e7e7782e66c578742428f6844da71b49"},"cell_type":"code","source":"# Compile the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(lr=LEARNING_RATE),\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74a45ebc15557c5f9e51f1ea7d7925d483257053"},"cell_type":"markdown","source":"### Train model\ntrain model using validation dataset for validate each steps"},{"metadata":{"trusted":true,"_uuid":"7a7a89eb3feda070990e1c91df1238db1b1a4033","scrolled":false},"cell_type":"code","source":"%%time\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n        epochs=EPOCHS,\n        validation_data=val_generator,\n        validation_steps=val_generator.samples//val_generator.batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a822adaaea01929ff19192f5b8c69e920e7bca3"},"cell_type":"code","source":"model.save(MODEL_PATH)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35beb3d22af95ba9cee886efc5a0a308399971de"},"cell_type":"markdown","source":"### Check Performance\nPlot training and validation accuracy and loss"},{"metadata":{"trusted":true,"_uuid":"665b81e94eefecc83b6ab86d0a6808b94f55e3fa"},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f8778915df3c6eb05b5478ac56f9435cc252598"},"cell_type":"markdown","source":"### Test model\nEvauate model using test dataset"},{"metadata":{"trusted":true,"_uuid":"94647dd2e4b1833baaf952a638683827dcd89eec"},"cell_type":"code","source":"%%time\nloss, accuracy = model.evaluate_generator(test_generator,steps=test_generator.samples//test_generator.batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9df2df2c68de760283d3d2041f67ea960bff06d6"},"cell_type":"code","source":"print(\"Accuracy: %f\\nLoss: %f\" % (accuracy,loss))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bac2db220779d93822310f4fb8a408d7f2c38d8f"},"cell_type":"markdown","source":"### Confusion Matrix\nBuild and plot confusion matrix"},{"metadata":{"trusted":true,"_uuid":"b2b889664350931364d44559933feede91382c4d"},"cell_type":"code","source":"%%time\nY_pred = model.predict_generator(test_generator,verbose=1, steps=test_generator.samples//test_generator.batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0aa42af22a40771b1a5ef59c7400345b3f8e39c"},"cell_type":"code","source":"y_pred = np.argmax(Y_pred, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efdb2469c036e5e73a9c3573f75fb1db43a13bdf"},"cell_type":"code","source":"cnf_matrix = confusion_matrix(test_generator.classes, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"204d814913a3331204914f0dfb53bb0338e09ee0"},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n\n    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    \n    plt.figure(figsize=(12,12))\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title, fontsize=18)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45, fontsize=8)\n    plt.yticks(tick_marks, classes, fontsize=12)\n\n    fmt = '.2f'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label', fontsize=16)\n    plt.xlabel('Predicted label', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d113d1f7f4a7966dbe62a7451f79a01f857fecf"},"cell_type":"code","source":"plot_confusion_matrix(cnf_matrix, list(classes.values()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae0a2f3c2bb2610e265c6a1531d08bd14b62d2de"},"cell_type":"markdown","source":"### Classification Report\nPrint classification report"},{"metadata":{"trusted":true,"_uuid":"45ea319b2e494ddf848066e660f4635de8218ed3"},"cell_type":"code","source":"print(classification_report(test_generator.classes, y_pred, target_names=list(classes.values())))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ecfdfbb963b78f3ec1d6f9c79a8e8b9c03fc07c"},"cell_type":"markdown","source":"### Random test\nRandom sample images from test dataset and predict "},{"metadata":{"trusted":true,"_uuid":"77ceb5ad732e71b6dc541e85acdfb9089d962fae"},"cell_type":"code","source":"def load_image(filename):\n    img = cv2.imread(os.path.join(BASE_DATASET_FOLDER, TEST_FOLDER, filename))\n    img = cv2.resize(img, (IMAGE_SIZE[0], IMAGE_SIZE[1]) )\n    img = img /255\n    \n    return img\n\n\ndef predict(image):\n    probabilities = model.predict(np.asarray([img]))[0]\n    class_idx = np.argmax(probabilities)\n    \n    return {classes[class_idx]: probabilities[class_idx]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"afb394e89bccf119d25a02516a4f01bfe79efc21"},"cell_type":"code","source":"for idx, filename in enumerate(random.sample(test_generator.filenames, 10)):\n    print(\"SOURCE: class: %s, file: %s\" % (os.path.split(filename)[0], filename))\n    \n    img = load_image(filename)\n    prediction = predict(img)\n    print(\"PREDICTED: class: %s, confidence: %f\" % (list(prediction.keys())[0], list(prediction.values())[0]))\n    plt.imshow(img)\n    plt.figure(idx)    \n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}